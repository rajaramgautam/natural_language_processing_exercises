{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16df3f0b",
   "metadata": {},
   "source": [
    "# NLP Modeling Lesson\n",
    "\n",
    "In this lesson, we'll do a bit of feature engineering, and then model our text data. We'll be aiming to predict whether a given text message is spam or not, and trying to predict the category of news articles.\n",
    "\n",
    "## Feature Extraction: TF-IDF\n",
    "- **TF**: Term Frequency; how often a particular word appears in a document. \n",
    "\n",
    "        \"apple\" appears in this document 15 times\n",
    "- **IDF**: Inverse Document Frequency; a measure of how many (related) documents contain a particular word. \n",
    "\n",
    "        \"apple\" is found in 10 of the 58 documents in our sample\n",
    "        \n",
    "- **TF-IDF**: A combination of the two measures above.\n",
    "\n",
    "### TF: Term Frequency\n",
    "\n",
    "Term frequency can be calculated in a number of ways, all of which reflect how frequently a word appears in a document.\n",
    "\n",
    "- **Raw Count**: This is simply the count of the number of occurances of each word.\n",
    "- **Frequency**: The number of times each word appears divided by the total number of words.\n",
    "- **Augmented Frequency**: The frequency of each word divided by the maximum frequency. This can help prevent bias towards larger documents.\n",
    "\n",
    "Let's take a look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28767537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from prepare import basic_clean, lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1c44f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       mary\n",
       "1        had\n",
       "2          a\n",
       "3     little\n",
       "4       lamb\n",
       "5          a\n",
       "6     little\n",
       "7       lamb\n",
       "8          a\n",
       "9     little\n",
       "10      lamb\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = 'Mary had a little lamb, a little lamb, a little lamb.'\n",
    "\n",
    "# clean up the text\n",
    "document = document.lower().replace(',', '').replace('.', '')\n",
    "# transform into a series\n",
    "words = pd.Series(document.split())\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459169ce",
   "metadata": {},
   "source": [
    "From the series we can extract the value_counts, which is our raw count for term frequency. Once we have the raw counts, we can calculate the other measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d942b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a         3\n",
       "little    3\n",
       "lamb      3\n",
       "mary      1\n",
       "had       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "784ec879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamb</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mary</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_count\n",
       "a               3\n",
       "little          3\n",
       "lamb            3\n",
       "mary            1\n",
       "had             1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lullaby = pd.DataFrame({'raw_count':words.value_counts()})\n",
    "lullaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9604b7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamb</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mary</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_count  frequency\n",
       "a               3   0.272727\n",
       "little          3   0.272727\n",
       "lamb            3   0.272727\n",
       "mary            1   0.090909\n",
       "had             1   0.090909"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lullaby['frequency'] = lullaby.raw_count.apply(lambda x: x/lullaby.raw_count.sum())\n",
    "lullaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f496ffd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "      <th>frequency</th>\n",
       "      <th>augmented_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamb</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mary</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_count  frequency  augmented_frequency\n",
       "a               3   0.272727             1.000000\n",
       "little          3   0.272727             1.000000\n",
       "lamb            3   0.272727             1.000000\n",
       "mary            1   0.090909             0.333333\n",
       "had             1   0.090909             0.333333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lullaby['augmented_frequency'] = lullaby.frequency.apply(lambda x: x/lullaby.frequency.max())\n",
    "lullaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3000d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "      <th>frequency</th>\n",
       "      <th>augmented_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamb</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mary</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_count  frequency  augmented_frequency\n",
       "a               3   0.272727             1.000000\n",
       "little          3   0.272727             1.000000\n",
       "lamb            3   0.272727             1.000000\n",
       "mary            1   0.090909             0.333333\n",
       "had             1   0.090909             0.333333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can accomplish the same task using fewer computational resources using .assign\n",
    "(pd.DataFrame({'raw_count': words.value_counts()})\n",
    " .assign(frequency=lambda df: df.raw_count / df.raw_count.sum())\n",
    " .assign(augmented_frequency=lambda df: df.frequency / df.frequency.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fba147",
   "metadata": {},
   "source": [
    "**Takeaways**: These are simply numeric representations of one characteristic of the strings in our corpus (frequency). Aside from simply showing us that some words are more frequent than others, this information by itself doesn't provide us much value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bdebed",
   "metadata": {},
   "source": [
    "## IDF: Inverse Document Frequency\n",
    "\n",
    "Inverse Document Frequency also provides information about individual words, but, in order to use this measure, we must have multiple documents, i.e. several different bodies of text.\n",
    "\n",
    "Inverse Document Frequency tells us how much **information** a word provides. It is based on how commonly a word appears across multiple documents. The metric is divised such that the more frequently a word appears, the lower the IDF for that word will be.\n",
    "\n",
    "      idf(word) = log(# of documents / # of documents containing word)\n",
    "      \n",
    "> If a given word doesn't appear in any documents, the denominator in the equation above would be zero, so some definitions of idf will add 1 to the denominator.\n",
    "\n",
    "For example, imagine we have 20 documents. We can visualize what the idf score looks like with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fac7bc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'IDF for a given word')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_documents = 20\n",
    "\n",
    "x = np.arange(1, n_documents + 1)\n",
    "y = np.log(n_documents / x)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(x, y, marker='.')\n",
    "\n",
    "plt.xticks(x)\n",
    "plt.xlabel('# of Documents the word appears in')\n",
    "plt.ylabel('IDF')\n",
    "plt.title('IDF for a given word')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f035fe18",
   "metadata": {},
   "source": [
    "**Takeaways**: Suppose you are trying to create a model that predicts whether a given corpus is written before 1900 or after 1900. If a word appears in every document of your sample, its not going to provide much insight. But if a word only appears in a small number of documents, then it could be representative of an underlying trend (i.e. \"afternoonified\" shows up in a small number of documents all of which were written before 1900).\n",
    "\n",
    "    High IDF = More information\n",
    "\n",
    "Let's look at an example of calculating IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "885eb660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': \"Codeup's data science program was created in response to a \"\n",
      "            'percieved lack of data science talent, and growing demand.',\n",
      " 'description': \"Codeup's data science program teaches hands on skills using \"\n",
      "                'Python and pandas.',\n",
      " 'news': 'Codeup announced last thursday that they just launched a new data '\n",
      "         'science program. It is 18 weeks long.'}\n",
      "\n",
      "Cleaning and lemmatizing...\n",
      "\n",
      "{'context': \"codeup's data science program wa created in response to a \"\n",
      "            'percieved lack of data science talent and growing demand',\n",
      " 'description': \"codeup's data science program teach hand on skill using \"\n",
      "                'python and panda',\n",
      " 'news': 'codeup announced last thursday that they just launched a new data '\n",
      "         'science program it is 18 week long'}\n"
     ]
    }
   ],
   "source": [
    "# our 3 example documents\n",
    "documents = {\n",
    "    'news': 'Codeup announced last thursday that they just launched a new data science program. It is 18 weeks long.',\n",
    "    'description': 'Codeup\\'s data science program teaches hands on skills using Python and pandas.',\n",
    "    'context': 'Codeup\\'s data science program was created in response to a percieved lack of data science talent, and growing demand.'\n",
    "}\n",
    "pprint(documents)\n",
    "\n",
    "print('\\nCleaning and lemmatizing...\\n')\n",
    "\n",
    "documents = {topic: lemmatize(basic_clean(documents[topic])) for topic in documents}\n",
    "pprint(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2ebbd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['codeup announced last thursday that they just launched a new data science program it is 18 week long', \"codeup's data science program teach hand on skill using python and panda\", \"codeup's data science program wa created in response to a percieved lack of data science talent and growing demand\"])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize document values to help explain our upcoming idf function\n",
    "documents.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4a39369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(word):\n",
    "    '''A simple way to calculate idf for demonstration. Note that this \n",
    "    function relies on a globally defined documents variable.'''\n",
    "    n_occurences = sum([1 for doc in documents.values() if word in doc])\n",
    "    return len(documents) / n_occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c13182e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['codeup', 'announced', 'last', 'thursday', 'that', 'they', 'just',\n",
       "       'launched', 'a', 'new', 'data', 'science', 'program', 'it', 'is',\n",
       "       '18', 'week', 'long', \"codeup's\", 'teach', 'hand', 'on', 'skill',\n",
       "       'using', 'python', 'and', 'panda', 'wa', 'created', 'in',\n",
       "       'response', 'to', 'percieved', 'lack', 'of', 'talent', 'growing',\n",
       "       'demand'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of the unique words\n",
    "unique_words = pd.Series(' '.join(documents.values()).split()).unique()\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd928fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>teach</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hand</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>using</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>panda</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wa</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>response</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percieved</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lack</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talent</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>growing</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announced</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>launched</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thursday</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>they</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codeup's</th>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>program</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codeup</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           idf\n",
       "word          \n",
       "teach      3.0\n",
       "created    3.0\n",
       "hand       3.0\n",
       "skill      3.0\n",
       "using      3.0\n",
       "python     3.0\n",
       "panda      3.0\n",
       "wa         3.0\n",
       "response   3.0\n",
       "long       3.0\n",
       "to         3.0\n",
       "percieved  3.0\n",
       "lack       3.0\n",
       "of         3.0\n",
       "talent     3.0\n",
       "growing    3.0\n",
       "announced  3.0\n",
       "demand     3.0\n",
       "new        3.0\n",
       "launched   3.0\n",
       "18         3.0\n",
       "last       3.0\n",
       "is         3.0\n",
       "it         3.0\n",
       "thursday   3.0\n",
       "that       3.0\n",
       "they       3.0\n",
       "just       3.0\n",
       "week       3.0\n",
       "codeup's   1.5\n",
       "in         1.5\n",
       "and        1.5\n",
       "a          1.0\n",
       "data       1.0\n",
       "science    1.0\n",
       "program    1.0\n",
       "on         1.0\n",
       "codeup     1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put the unique words into a data frame\n",
    "(pd.DataFrame(dict(word=unique_words))\n",
    " # calculate the idf for each word\n",
    " .assign(idf=lambda df: df.word.apply(idf))\n",
    " # sort the data for presentation purposes\n",
    " .set_index('word')\n",
    " .sort_values(by='idf', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23001665",
   "metadata": {},
   "source": [
    "**Takeaways**: Words with the lowest IDF score were found in every document. They do us no good in helping us to distinguish whether a given corpus was \"context\", \"description\", or \"news\". Words with high IDF scores are more strongly linked to a particular classification. \n",
    "\n",
    "But this sample is so small that we should be cautious in using the word \"on\" as a means to classify a future corpus. \n",
    "\n",
    "> The calculation for an individual IDF score requires a word **and** a set of documents.\n",
    "\n",
    "## TF-IDF\n",
    "\n",
    "TF-IDF is simply the multiplication of the two metrics we've discussed above. Let's calculate an TF-IDF for all of the words and documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5bd75de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('news', 'codeup announced last thursday that they just launched a new data science program it is 18 week long'), ('description', \"codeup's data science program teach hand on skill using python and panda\"), ('context', \"codeup's data science program wa created in response to a percieved lack of data science talent and growing demand\")])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will create an empty list to store values for us as we iterate through our data\n",
    "tfs = []\n",
    "\n",
    "# Start by iterating over all the documents. We can use .items() to speed up our loop:\n",
    "documents.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc91974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a for loop\n",
    "for doc, text in documents.items():\n",
    "    # We will make a dataframe that contains the term frequency for every word\n",
    "    df = (pd.Series(text.split())\n",
    "          .value_counts()\n",
    "          .reset_index()\n",
    "          .set_axis(['word', 'raw_count'], axis=1, inplace=False)\n",
    "          .assign(tf=lambda df: df.raw_count / df.shape[0])\n",
    "          .drop(columns='raw_count')\n",
    "          .assign(doc=doc))\n",
    "    # Then add that data frame to our list\n",
    "    tfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e19375ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGINNING LOOP\n",
      "\n",
      "\n",
      "Text being manipulated:\n",
      "-----------------------------------------\n",
      "Document: news\n",
      "Text: codeup announced last thursday that they just launched a new data science program it is 18 week long\n",
      "\n",
      "\n",
      "Step 1: Splitting the corpus into a list of words\n",
      "df = (pd.Series(text.split()))\n",
      "-----------------------------------------\n",
      "0        codeup\n",
      "1     announced\n",
      "2          last\n",
      "3      thursday\n",
      "4          that\n",
      "5          they\n",
      "6          just\n",
      "7      launched\n",
      "8             a\n",
      "9           new\n",
      "10         data\n",
      "11      science\n",
      "12      program\n",
      "13           it\n",
      "14           is\n",
      "15           18\n",
      "16         week\n",
      "17         long\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Step 2: Converting list of words into a value count array\n",
      "df = df.value_counts()\n",
      "-----------------------------------------\n",
      "codeup       1\n",
      "announced    1\n",
      "week         1\n",
      "18           1\n",
      "is           1\n",
      "it           1\n",
      "program      1\n",
      "science      1\n",
      "data         1\n",
      "new          1\n",
      "a            1\n",
      "launched     1\n",
      "just         1\n",
      "they         1\n",
      "that         1\n",
      "thursday     1\n",
      "last         1\n",
      "long         1\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Step 3: Resetting the index\n",
      "df = df.reset_index()\n",
      "-----------------------------------------\n",
      "        index  0\n",
      "0      codeup  1\n",
      "1   announced  1\n",
      "2        week  1\n",
      "3          18  1\n",
      "4          is  1\n",
      "5          it  1\n",
      "6     program  1\n",
      "7     science  1\n",
      "8        data  1\n",
      "9         new  1\n",
      "10          a  1\n",
      "11   launched  1\n",
      "12       just  1\n",
      "13       they  1\n",
      "14       that  1\n",
      "15   thursday  1\n",
      "16       last  1\n",
      "17       long  1\n",
      "\n",
      "\n",
      "Step 4: Relabeling the columns\n",
      "df = df.set_axis(['word', 'raw_count'], axis=1, inplace=False)\n",
      "-----------------------------------------\n",
      "         word  raw_count\n",
      "0      codeup          1\n",
      "1   announced          1\n",
      "2        week          1\n",
      "3          18          1\n",
      "4          is          1\n",
      "5          it          1\n",
      "6     program          1\n",
      "7     science          1\n",
      "8        data          1\n",
      "9         new          1\n",
      "10          a          1\n",
      "11   launched          1\n",
      "12       just          1\n",
      "13       they          1\n",
      "14       that          1\n",
      "15   thursday          1\n",
      "16       last          1\n",
      "17       long          1\n",
      "\n",
      "\n",
      "Step 5: Calculating the Term Frequency of Each Word within this one corpus\n",
      "df['tf'] = df.raw_count.apply(lambda x: x/df.shape[0])\n",
      "-----------------------------------------\n",
      "         word  raw_count        tf\n",
      "0      codeup          1  0.055556\n",
      "1   announced          1  0.055556\n",
      "2        week          1  0.055556\n",
      "3          18          1  0.055556\n",
      "4          is          1  0.055556\n",
      "5          it          1  0.055556\n",
      "6     program          1  0.055556\n",
      "7     science          1  0.055556\n",
      "8        data          1  0.055556\n",
      "9         new          1  0.055556\n",
      "10          a          1  0.055556\n",
      "11   launched          1  0.055556\n",
      "12       just          1  0.055556\n",
      "13       they          1  0.055556\n",
      "14       that          1  0.055556\n",
      "15   thursday          1  0.055556\n",
      "16       last          1  0.055556\n",
      "17       long          1  0.055556\n",
      "\n",
      "\n",
      "Step 6: Dropping the 'raw_count' column\n",
      "df = df.drop(columns='raw_count')\n",
      "-----------------------------------------\n",
      "         word        tf\n",
      "0      codeup  0.055556\n",
      "1   announced  0.055556\n",
      "2        week  0.055556\n",
      "3          18  0.055556\n",
      "4          is  0.055556\n",
      "5          it  0.055556\n",
      "6     program  0.055556\n",
      "7     science  0.055556\n",
      "8        data  0.055556\n",
      "9         new  0.055556\n",
      "10          a  0.055556\n",
      "11   launched  0.055556\n",
      "12       just  0.055556\n",
      "13       they  0.055556\n",
      "14       that  0.055556\n",
      "15   thursday  0.055556\n",
      "16       last  0.055556\n",
      "17       long  0.055556\n",
      "\n",
      "\n",
      "Step 6: Adding the document label for this corpus\n",
      "df['doc'] = doc\n",
      "-----------------------------------------\n",
      "         word        tf   doc\n",
      "0      codeup  0.055556  news\n",
      "1   announced  0.055556  news\n",
      "2        week  0.055556  news\n",
      "3          18  0.055556  news\n",
      "4          is  0.055556  news\n",
      "5          it  0.055556  news\n",
      "6     program  0.055556  news\n",
      "7     science  0.055556  news\n",
      "8        data  0.055556  news\n",
      "9         new  0.055556  news\n",
      "10          a  0.055556  news\n",
      "11   launched  0.055556  news\n",
      "12       just  0.055556  news\n",
      "13       they  0.055556  news\n",
      "14       that  0.055556  news\n",
      "15   thursday  0.055556  news\n",
      "16       last  0.055556  news\n",
      "17       long  0.055556  news\n",
      "\n",
      "\n",
      "ITERATION OF ELEMENT COMPLETE\n",
      "\n",
      " \n",
      "\n",
      "Text being manipulated:\n",
      "-----------------------------------------\n",
      "Document: description\n",
      "Text: codeup's data science program teach hand on skill using python and panda\n",
      "\n",
      "\n",
      "Step 1: Splitting the corpus into a list of words\n",
      "df = (pd.Series(text.split()))\n",
      "-----------------------------------------\n",
      "0     codeup's\n",
      "1         data\n",
      "2      science\n",
      "3      program\n",
      "4        teach\n",
      "5         hand\n",
      "6           on\n",
      "7        skill\n",
      "8        using\n",
      "9       python\n",
      "10         and\n",
      "11       panda\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Step 2: Converting list of words into a value count array\n",
      "df = df.value_counts()\n",
      "-----------------------------------------\n",
      "codeup's    1\n",
      "data        1\n",
      "science     1\n",
      "program     1\n",
      "teach       1\n",
      "hand        1\n",
      "on          1\n",
      "skill       1\n",
      "using       1\n",
      "python      1\n",
      "and         1\n",
      "panda       1\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Step 3: Resetting the index\n",
      "df = df.reset_index()\n",
      "-----------------------------------------\n",
      "       index  0\n",
      "0   codeup's  1\n",
      "1       data  1\n",
      "2    science  1\n",
      "3    program  1\n",
      "4      teach  1\n",
      "5       hand  1\n",
      "6         on  1\n",
      "7      skill  1\n",
      "8      using  1\n",
      "9     python  1\n",
      "10       and  1\n",
      "11     panda  1\n",
      "\n",
      "\n",
      "Step 4: Relabeling the columns\n",
      "df = df.set_axis(['word', 'raw_count'], axis=1, inplace=False)\n",
      "-----------------------------------------\n",
      "        word  raw_count\n",
      "0   codeup's          1\n",
      "1       data          1\n",
      "2    science          1\n",
      "3    program          1\n",
      "4      teach          1\n",
      "5       hand          1\n",
      "6         on          1\n",
      "7      skill          1\n",
      "8      using          1\n",
      "9     python          1\n",
      "10       and          1\n",
      "11     panda          1\n",
      "\n",
      "\n",
      "Step 5: Calculating the Term Frequency of Each Word within this one corpus\n",
      "df['tf'] = df.raw_count.apply(lambda x: x/df.shape[0])\n",
      "-----------------------------------------\n",
      "        word  raw_count        tf\n",
      "0   codeup's          1  0.083333\n",
      "1       data          1  0.083333\n",
      "2    science          1  0.083333\n",
      "3    program          1  0.083333\n",
      "4      teach          1  0.083333\n",
      "5       hand          1  0.083333\n",
      "6         on          1  0.083333\n",
      "7      skill          1  0.083333\n",
      "8      using          1  0.083333\n",
      "9     python          1  0.083333\n",
      "10       and          1  0.083333\n",
      "11     panda          1  0.083333\n",
      "\n",
      "\n",
      "Step 6: Dropping the 'raw_count' column\n",
      "df = df.drop(columns='raw_count')\n",
      "-----------------------------------------\n",
      "        word        tf\n",
      "0   codeup's  0.083333\n",
      "1       data  0.083333\n",
      "2    science  0.083333\n",
      "3    program  0.083333\n",
      "4      teach  0.083333\n",
      "5       hand  0.083333\n",
      "6         on  0.083333\n",
      "7      skill  0.083333\n",
      "8      using  0.083333\n",
      "9     python  0.083333\n",
      "10       and  0.083333\n",
      "11     panda  0.083333\n",
      "\n",
      "\n",
      "Step 6: Adding the document label for this corpus\n",
      "df['doc'] = doc\n",
      "-----------------------------------------\n",
      "        word        tf          doc\n",
      "0   codeup's  0.083333  description\n",
      "1       data  0.083333  description\n",
      "2    science  0.083333  description\n",
      "3    program  0.083333  description\n",
      "4      teach  0.083333  description\n",
      "5       hand  0.083333  description\n",
      "6         on  0.083333  description\n",
      "7      skill  0.083333  description\n",
      "8      using  0.083333  description\n",
      "9     python  0.083333  description\n",
      "10       and  0.083333  description\n",
      "11     panda  0.083333  description\n",
      "\n",
      "\n",
      "ITERATION OF ELEMENT COMPLETE\n",
      "\n",
      " \n",
      "\n",
      "Text being manipulated:\n",
      "-----------------------------------------\n",
      "Document: context\n",
      "Text: codeup's data science program wa created in response to a percieved lack of data science talent and growing demand\n",
      "\n",
      "\n",
      "Step 1: Splitting the corpus into a list of words\n",
      "df = (pd.Series(text.split()))\n",
      "-----------------------------------------\n",
      "0      codeup's\n",
      "1          data\n",
      "2       science\n",
      "3       program\n",
      "4            wa\n",
      "5       created\n",
      "6            in\n",
      "7      response\n",
      "8            to\n",
      "9             a\n",
      "10    percieved\n",
      "11         lack\n",
      "12           of\n",
      "13         data\n",
      "14      science\n",
      "15       talent\n",
      "16          and\n",
      "17      growing\n",
      "18       demand\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Step 2: Converting list of words into a value count array\n",
      "df = df.value_counts()\n",
      "-----------------------------------------\n",
      "science      2\n",
      "data         2\n",
      "codeup's     1\n",
      "percieved    1\n",
      "growing      1\n",
      "and          1\n",
      "talent       1\n",
      "of           1\n",
      "lack         1\n",
      "to           1\n",
      "a            1\n",
      "response     1\n",
      "in           1\n",
      "created      1\n",
      "wa           1\n",
      "program      1\n",
      "demand       1\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Step 3: Resetting the index\n",
      "df = df.reset_index()\n",
      "-----------------------------------------\n",
      "        index  0\n",
      "0     science  2\n",
      "1        data  2\n",
      "2    codeup's  1\n",
      "3   percieved  1\n",
      "4     growing  1\n",
      "5         and  1\n",
      "6      talent  1\n",
      "7          of  1\n",
      "8        lack  1\n",
      "9          to  1\n",
      "10          a  1\n",
      "11   response  1\n",
      "12         in  1\n",
      "13    created  1\n",
      "14         wa  1\n",
      "15    program  1\n",
      "16     demand  1\n",
      "\n",
      "\n",
      "Step 4: Relabeling the columns\n",
      "df = df.set_axis(['word', 'raw_count'], axis=1, inplace=False)\n",
      "-----------------------------------------\n",
      "         word  raw_count\n",
      "0     science          2\n",
      "1        data          2\n",
      "2    codeup's          1\n",
      "3   percieved          1\n",
      "4     growing          1\n",
      "5         and          1\n",
      "6      talent          1\n",
      "7          of          1\n",
      "8        lack          1\n",
      "9          to          1\n",
      "10          a          1\n",
      "11   response          1\n",
      "12         in          1\n",
      "13    created          1\n",
      "14         wa          1\n",
      "15    program          1\n",
      "16     demand          1\n",
      "\n",
      "\n",
      "Step 5: Calculating the Term Frequency of Each Word within this one corpus\n",
      "df['tf'] = df.raw_count.apply(lambda x: x/df.shape[0])\n",
      "-----------------------------------------\n",
      "         word  raw_count        tf\n",
      "0     science          2  0.117647\n",
      "1        data          2  0.117647\n",
      "2    codeup's          1  0.058824\n",
      "3   percieved          1  0.058824\n",
      "4     growing          1  0.058824\n",
      "5         and          1  0.058824\n",
      "6      talent          1  0.058824\n",
      "7          of          1  0.058824\n",
      "8        lack          1  0.058824\n",
      "9          to          1  0.058824\n",
      "10          a          1  0.058824\n",
      "11   response          1  0.058824\n",
      "12         in          1  0.058824\n",
      "13    created          1  0.058824\n",
      "14         wa          1  0.058824\n",
      "15    program          1  0.058824\n",
      "16     demand          1  0.058824\n",
      "\n",
      "\n",
      "Step 6: Dropping the 'raw_count' column\n",
      "df = df.drop(columns='raw_count')\n",
      "-----------------------------------------\n",
      "         word        tf\n",
      "0     science  0.117647\n",
      "1        data  0.117647\n",
      "2    codeup's  0.058824\n",
      "3   percieved  0.058824\n",
      "4     growing  0.058824\n",
      "5         and  0.058824\n",
      "6      talent  0.058824\n",
      "7          of  0.058824\n",
      "8        lack  0.058824\n",
      "9          to  0.058824\n",
      "10          a  0.058824\n",
      "11   response  0.058824\n",
      "12         in  0.058824\n",
      "13    created  0.058824\n",
      "14         wa  0.058824\n",
      "15    program  0.058824\n",
      "16     demand  0.058824\n",
      "\n",
      "\n",
      "Step 6: Adding the document label for this corpus\n",
      "df['doc'] = doc\n",
      "-----------------------------------------\n",
      "         word        tf      doc\n",
      "0     science  0.117647  context\n",
      "1        data  0.117647  context\n",
      "2    codeup's  0.058824  context\n",
      "3   percieved  0.058824  context\n",
      "4     growing  0.058824  context\n",
      "5         and  0.058824  context\n",
      "6      talent  0.058824  context\n",
      "7          of  0.058824  context\n",
      "8        lack  0.058824  context\n",
      "9          to  0.058824  context\n",
      "10          a  0.058824  context\n",
      "11   response  0.058824  context\n",
      "12         in  0.058824  context\n",
      "13    created  0.058824  context\n",
      "14         wa  0.058824  context\n",
      "15    program  0.058824  context\n",
      "16     demand  0.058824  context\n",
      "\n",
      "\n",
      "ITERATION OF ELEMENT COMPLETE\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What actually happened in that code block? Overexplanation using print statements:\n",
    "print(\"BEGINNING LOOP\")\n",
    "print(\"\\n\")\n",
    "for doc, text in documents.items():\n",
    "    print(\"Text being manipulated:\")\n",
    "    print('-----------------------------------------')\n",
    "    print(f'Document: {doc}')\n",
    "    print(f'Text: {text}')\n",
    "    print('\\n')\n",
    "    print(\"Step 1: Splitting the corpus into a list of words\")\n",
    "    print(\"df = (pd.Series(text.split()))\")\n",
    "    print('-----------------------------------------')\n",
    "    df = (pd.Series(text.split()))\n",
    "    print(df)\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"Step 2: Converting list of words into a value count array\")\n",
    "    print(\"df = df.value_counts()\")\n",
    "    print('-----------------------------------------')\n",
    "    df = df.value_counts()\n",
    "    print(df)\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"Step 3: Resetting the index\")\n",
    "    print(\"df = df.reset_index()\")\n",
    "    print('-----------------------------------------')\n",
    "    df = df.reset_index()\n",
    "    print(df)\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"Step 4: Relabeling the columns\")\n",
    "    print(\"df = df.set_axis(['word', 'raw_count'], axis=1, inplace=False)\")\n",
    "    print('-----------------------------------------')    \n",
    "    df = df.set_axis(['word', 'raw_count'], axis=1, inplace=False)\n",
    "    print(df)\n",
    "    print('\\n')    \n",
    "    \n",
    "    print(\"Step 5: Calculating the Term Frequency of Each Word within this one corpus\")\n",
    "    print(\"df['tf'] = df.raw_count.apply(lambda x: x/df.shape[0])\")\n",
    "    print('-----------------------------------------')      \n",
    "    df['tf'] = df.raw_count.apply(lambda x: x/df.shape[0])\n",
    "    print(df)\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"Step 6: Dropping the 'raw_count' column\")\n",
    "    print(\"df = df.drop(columns='raw_count')\")\n",
    "    print('-----------------------------------------')      \n",
    "    df = df.drop(columns='raw_count')\n",
    "    print(df)\n",
    "    print('\\n')    \n",
    "    \n",
    "    print(\"Step 6: Adding the document label for this corpus\")\n",
    "    print(\"df['doc'] = doc\")\n",
    "    print('-----------------------------------------') \n",
    "    df['doc'] = doc\n",
    "    print(df)\n",
    "    print('\\n')\n",
    "    print(\"ITERATION OF ELEMENT COMPLETE\")\n",
    "    print('\\n', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2059a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[         word        tf   doc\n",
       " 0      codeup  0.055556  news\n",
       " 1   announced  0.055556  news\n",
       " 2        week  0.055556  news\n",
       " 3          18  0.055556  news\n",
       " 4          is  0.055556  news\n",
       " 5          it  0.055556  news\n",
       " 6     program  0.055556  news\n",
       " 7     science  0.055556  news\n",
       " 8        data  0.055556  news\n",
       " 9         new  0.055556  news\n",
       " 10          a  0.055556  news\n",
       " 11   launched  0.055556  news\n",
       " 12       just  0.055556  news\n",
       " 13       they  0.055556  news\n",
       " 14       that  0.055556  news\n",
       " 15   thursday  0.055556  news\n",
       " 16       last  0.055556  news\n",
       " 17       long  0.055556  news,\n",
       "         word        tf          doc\n",
       " 0   codeup's  0.083333  description\n",
       " 1       data  0.083333  description\n",
       " 2    science  0.083333  description\n",
       " 3    program  0.083333  description\n",
       " 4      teach  0.083333  description\n",
       " 5       hand  0.083333  description\n",
       " 6         on  0.083333  description\n",
       " 7      skill  0.083333  description\n",
       " 8      using  0.083333  description\n",
       " 9     python  0.083333  description\n",
       " 10       and  0.083333  description\n",
       " 11     panda  0.083333  description,\n",
       "          word        tf      doc\n",
       " 0     science  0.117647  context\n",
       " 1        data  0.117647  context\n",
       " 2    codeup's  0.058824  context\n",
       " 3   percieved  0.058824  context\n",
       " 4     growing  0.058824  context\n",
       " 5         and  0.058824  context\n",
       " 6      talent  0.058824  context\n",
       " 7          of  0.058824  context\n",
       " 8        lack  0.058824  context\n",
       " 9          to  0.058824  context\n",
       " 10          a  0.058824  context\n",
       " 11   response  0.058824  context\n",
       " 12         in  0.058824  context\n",
       " 13    created  0.058824  context\n",
       " 14         wa  0.058824  context\n",
       " 15    program  0.058824  context\n",
       " 16     demand  0.058824  context]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "494a7ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>doc</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hand</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>teach</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>panda</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>python</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>using</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>skill</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wa</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>created</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>response</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>to</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lack</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>of</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>talent</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>growing</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>percieved</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>demand</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>last</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>long</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>week</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>is</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>thursday</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>announced</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>it</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>that</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>they</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>just</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>launched</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>new</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>codeup's</td>\n",
       "      <td>description</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>and</td>\n",
       "      <td>description</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>data</td>\n",
       "      <td>context</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>science</td>\n",
       "      <td>context</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>codeup's</td>\n",
       "      <td>context</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>and</td>\n",
       "      <td>context</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>in</td>\n",
       "      <td>context</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>on</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>program</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>science</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>data</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>a</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>program</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>a</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>data</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>science</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>program</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>codeup</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word          doc    tf_idf\n",
       "0        hand  description  0.250000\n",
       "1       teach  description  0.250000\n",
       "2       panda  description  0.250000\n",
       "3      python  description  0.250000\n",
       "4       using  description  0.250000\n",
       "5       skill  description  0.250000\n",
       "6          wa      context  0.176471\n",
       "7     created      context  0.176471\n",
       "8    response      context  0.176471\n",
       "9          to      context  0.176471\n",
       "10       lack      context  0.176471\n",
       "11         of      context  0.176471\n",
       "12     talent      context  0.176471\n",
       "13    growing      context  0.176471\n",
       "14  percieved      context  0.176471\n",
       "15     demand      context  0.176471\n",
       "16       last         news  0.166667\n",
       "17       long         news  0.166667\n",
       "18       week         news  0.166667\n",
       "19         18         news  0.166667\n",
       "20         is         news  0.166667\n",
       "21   thursday         news  0.166667\n",
       "22  announced         news  0.166667\n",
       "23         it         news  0.166667\n",
       "24       that         news  0.166667\n",
       "25       they         news  0.166667\n",
       "26       just         news  0.166667\n",
       "27   launched         news  0.166667\n",
       "28        new         news  0.166667\n",
       "29   codeup's  description  0.125000\n",
       "30        and  description  0.125000\n",
       "31       data      context  0.117647\n",
       "32    science      context  0.117647\n",
       "33   codeup's      context  0.088235\n",
       "34        and      context  0.088235\n",
       "35         in      context  0.088235\n",
       "36         on  description  0.083333\n",
       "37    program  description  0.083333\n",
       "38    science  description  0.083333\n",
       "39       data  description  0.083333\n",
       "40          a      context  0.058824\n",
       "41    program      context  0.058824\n",
       "42          a         news  0.055556\n",
       "43       data         news  0.055556\n",
       "44    science         news  0.055556\n",
       "45    program         news  0.055556\n",
       "46     codeup         news  0.055556"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll then concatenate all the tf values together.\n",
    "(pd.concat(tfs)\n",
    " # calculate the idf value for each word\n",
    " .assign(idf=lambda df: df.word.apply(idf))\n",
    " # then use the if and idf values to calculate tf-idf \n",
    " .assign(tf_idf=lambda df: df.idf * df.tf)\n",
    " .drop(columns=['tf', 'idf'])\n",
    " .sort_values(by='tf_idf', ascending=False)\n",
    " .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a945e1b",
   "metadata": {},
   "source": [
    "It's more common to see the data presented with the words as features, and the documents as observations, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5352734a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF for each word/doc combination\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>word</th>\n",
       "      <th>18</th>\n",
       "      <th>a</th>\n",
       "      <th>and</th>\n",
       "      <th>announced</th>\n",
       "      <th>codeup</th>\n",
       "      <th>codeup's</th>\n",
       "      <th>created</th>\n",
       "      <th>data</th>\n",
       "      <th>demand</th>\n",
       "      <th>growing</th>\n",
       "      <th>...</th>\n",
       "      <th>skill</th>\n",
       "      <th>talent</th>\n",
       "      <th>teach</th>\n",
       "      <th>that</th>\n",
       "      <th>they</th>\n",
       "      <th>thursday</th>\n",
       "      <th>to</th>\n",
       "      <th>using</th>\n",
       "      <th>wa</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>context</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "word               18         a       and  announced    codeup  codeup's  \\\n",
       "doc                                                                        \n",
       "context      0.000000  0.058824  0.088235   0.000000  0.000000  0.088235   \n",
       "description  0.000000  0.000000  0.125000   0.000000  0.000000  0.125000   \n",
       "news         0.166667  0.055556  0.000000   0.166667  0.055556  0.000000   \n",
       "\n",
       "word          created      data    demand   growing  ...  skill    talent  \\\n",
       "doc                                                  ...                    \n",
       "context      0.176471  0.117647  0.176471  0.176471  ...   0.00  0.176471   \n",
       "description  0.000000  0.083333  0.000000  0.000000  ...   0.25  0.000000   \n",
       "news         0.000000  0.055556  0.000000  0.000000  ...   0.00  0.000000   \n",
       "\n",
       "word         teach      that      they  thursday        to  using        wa  \\\n",
       "doc                                                                           \n",
       "context       0.00  0.000000  0.000000  0.000000  0.176471   0.00  0.176471   \n",
       "description   0.25  0.000000  0.000000  0.000000  0.000000   0.25  0.000000   \n",
       "news          0.00  0.166667  0.166667  0.166667  0.000000   0.00  0.000000   \n",
       "\n",
       "word             week  \n",
       "doc                    \n",
       "context      0.000000  \n",
       "description  0.000000  \n",
       "news         0.166667  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll then concatenate all the tf values together.\n",
    "print(\"TF-IDF for each word/doc combination\")\n",
    "(pd.concat(tfs)\n",
    " # calculate the idf value for each word\n",
    " .assign(idf=lambda df: df.word.apply(idf))\n",
    " # then use the if and idf values to calculate tf-idf \n",
    " .assign(tf_idf=lambda df: df.idf * df.tf)\n",
    " .drop(columns=['tf', 'idf'])\n",
    " .sort_values(by='tf_idf', ascending=False)\n",
    " .pipe(lambda df: pd.crosstab(df.doc, df.word, values=df.tf_idf, aggfunc=lambda x: x))\n",
    " .fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb2dd7a",
   "metadata": {},
   "source": [
    "## TF-IDF with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2061d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x36 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 45 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidfs = tfidf.fit_transform(documents.values())\n",
    "tfidfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1c0e1d",
   "metadata": {},
   "source": [
    "We get back a sparse matrix, a matrix with more 0s than anything else. Numpy has a special type that makes some manipulations and operations faster on sparse matrices.\n",
    "\n",
    "Becuase our data set is pretty small, we can convert our sparse matrix to a regular one, and put everything in a dataframe. If our data were larger, the operation below might take much longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e094dc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>18</th>\n",
       "      <th>and</th>\n",
       "      <th>announced</th>\n",
       "      <th>codeup</th>\n",
       "      <th>created</th>\n",
       "      <th>data</th>\n",
       "      <th>demand</th>\n",
       "      <th>growing</th>\n",
       "      <th>hand</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>skill</th>\n",
       "      <th>talent</th>\n",
       "      <th>teach</th>\n",
       "      <th>that</th>\n",
       "      <th>they</th>\n",
       "      <th>thursday</th>\n",
       "      <th>to</th>\n",
       "      <th>using</th>\n",
       "      <th>wa</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.263566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263566</td>\n",
       "      <td>0.155666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263566</td>\n",
       "      <td>0.263566</td>\n",
       "      <td>0.263566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.253880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152159</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>0.304317</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         18       and  announced    codeup   created      data    demand  \\\n",
       "0  0.263566  0.000000   0.263566  0.155666  0.000000  0.155666  0.000000   \n",
       "1  0.000000  0.253880   0.000000  0.197160  0.000000  0.197160  0.000000   \n",
       "2  0.000000  0.195932   0.000000  0.152159  0.257627  0.304317  0.257627   \n",
       "\n",
       "    growing      hand        in  ...     skill    talent     teach      that  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.263566   \n",
       "1  0.000000  0.333821  0.000000  ...  0.333821  0.000000  0.333821  0.000000   \n",
       "2  0.257627  0.000000  0.257627  ...  0.000000  0.257627  0.000000  0.000000   \n",
       "\n",
       "       they  thursday        to     using        wa      week  \n",
       "0  0.263566  0.263566  0.000000  0.000000  0.000000  0.263566  \n",
       "1  0.000000  0.000000  0.000000  0.333821  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.257627  0.000000  0.257627  0.000000  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidfs.todense(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0762a2",
   "metadata": {},
   "source": [
    "Why are the values different? Because in our manual version we used a simplified formula. Scikit-learn uses the proper IDF formula to calculate TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba1f038",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Now we'll use the computed TF-IDF values as features in a model. We'll take a look at the spam data set first.\n",
    "\n",
    "Because of the way we are modeling the data, we have a lot of columns, and it is not uncommon to have more columns than rows. Also, our data is very imbalanced in the class distribution, that is, there are many more ham messages than spam messages.\n",
    "\n",
    "Other than these considerations, we can treat this as a standard classification problem. We'll use logistic regression as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8112d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from env import user, password, host\n",
    "\n",
    "def get_db_url(database, host=host, user=user, password=password):\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{database}'\n",
    "\n",
    "url = get_db_url(\"spam_db\")\n",
    "sql = \"SELECT * FROM spam\"\n",
    "\n",
    "df = pd.read_sql(sql, url, index_col=\"id\")\n",
    "df.head()\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df.text)\n",
    "y = df.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train['predicted'] = lm.predict(X_train)\n",
    "test['predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae14f2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.67%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3857   102\n",
      "spam          2   496\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      3859\n",
      "        spam       1.00      0.83      0.91       598\n",
      "\n",
      "    accuracy                           0.98      4457\n",
      "   macro avg       0.99      0.91      0.95      4457\n",
      "weighted avg       0.98      0.98      0.98      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96c3bad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.78%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        964    45\n",
      "spam         2   104\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98       966\n",
      "        spam       0.98      0.70      0.82       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.97      0.85      0.90      1115\n",
      "weighted avg       0.96      0.96      0.95      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533b30e5",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Do your work for this exercise in a file named `model.ipynb`.\n",
    "\n",
    "Take the work we did in the lessons further:\n",
    "\n",
    "1. What other types of models (i.e. different classifcation algorithms) could you use? Create a model with a different algorithm.\n",
    "2. How do the models compare when trained on term frequency data alone, instead of TF-IDF values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd2d24f",
   "metadata": {},
   "source": [
    "### 1. What other types of models (i.e. different classifcation algorithms) could you use? Create a model with a different algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4616a08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from env import user, password, host\n",
    "\n",
    "def get_db_url(database, host=host, user=user, password=password):\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{database}'\n",
    "\n",
    "url = get_db_url(\"spam_db\")\n",
    "sql = \"SELECT * FROM spam\"\n",
    "\n",
    "df = pd.read_sql(sql, url, index_col=\"id\")\n",
    "df.head()\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df.text)\n",
    "y = df.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed0f929",
   "metadata": {},
   "source": [
    "# Model 2 : Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "33292815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping max_depth as 10 and creating our model\n",
    "tree = DecisionTreeClassifier(max_depth = 5, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0c0aecc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, random_state=123)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting our model\n",
    "\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3d12559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tree_predicted'] = tree.predict(X_train)\n",
    "test['tree_predicted'] = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a28c40ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9602871886919453"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating accuracy\n",
    "\n",
    "tree.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4cb68a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 96.03%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual           ham  spam\n",
      "tree_predicted            \n",
      "ham             3851   169\n",
      "spam               8   429\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98      3859\n",
      "        spam       0.98      0.72      0.83       598\n",
      "\n",
      "    accuracy                           0.96      4457\n",
      "   macro avg       0.97      0.86      0.90      4457\n",
      "weighted avg       0.96      0.96      0.96      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy : {:.2%}'.format(accuracy_score(train.actual, train.tree_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.tree_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.tree_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faff14a",
   "metadata": {},
   "source": [
    "# Model 3: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4620a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a model with max_depth of 10, and min samples leaf of 5\n",
    "forest = RandomForestClassifier(random_state = 139, max_depth = 10, min_samples_leaf = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d6e7a40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_leaf=5, random_state=139)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting our model\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "14636d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['forest_predicted'] = forest.predict(X_train)\n",
    "test['forest_predicted'] = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bf691ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9037469149652232"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "forest.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f1552318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 90.37%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual             ham  spam\n",
      "forest_predicted            \n",
      "ham               3859   429\n",
      "spam                 0   169\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.90      1.00      0.95      3859\n",
      "        spam       1.00      0.28      0.44       598\n",
      "\n",
      "    accuracy                           0.90      4457\n",
      "   macro avg       0.95      0.64      0.69      4457\n",
      "weighted avg       0.91      0.90      0.88      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy : {:.2%}'.format(accuracy_score(train.actual, train.forest_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.forest_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.forest_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b72c4b",
   "metadata": {},
   "source": [
    "# Model 4: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c24e3b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f9d09a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=10)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting our model\n",
    "\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9ab39f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['knn_predicted'] = knn.predict(X_train)\n",
    "test['knn_predicted'] = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a8eba249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9591653578640341"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating accuracy\n",
    "knn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "77053ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 95.92%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual          ham  spam\n",
      "knn_predicted            \n",
      "ham            3859   182\n",
      "spam              0   416\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      1.00      0.98      3859\n",
      "        spam       1.00      0.70      0.82       598\n",
      "\n",
      "    accuracy                           0.96      4457\n",
      "   macro avg       0.98      0.85      0.90      4457\n",
      "weighted avg       0.96      0.96      0.96      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy : {:.2%}'.format(accuracy_score(train.actual, train.knn_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.knn_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.knn_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba99b5",
   "metadata": {},
   "source": [
    "# 2. How do the models compare when trained on term frequency data alone, instead of TF-IDF values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aba3358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create an object\n",
    "count_vect = CountVectorizer()\n",
    "X_bag_of_words = count_vect.fit_transform(df.text)\n",
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6a8378db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bag_of_words.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5e061ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '000pes',\n",
       " '008704050406',\n",
       " '0089',\n",
       " '0121',\n",
       " '01223585236',\n",
       " '01223585334',\n",
       " '0125698789',\n",
       " '02',\n",
       " '0207',\n",
       " '02072069400',\n",
       " '02073162414',\n",
       " '02085076972',\n",
       " '021',\n",
       " '03',\n",
       " '04',\n",
       " '0430',\n",
       " '05',\n",
       " '050703',\n",
       " '0578',\n",
       " '06',\n",
       " '07',\n",
       " '07008009200',\n",
       " '07046744435',\n",
       " '07090201529',\n",
       " '07090298926',\n",
       " '07099833605',\n",
       " '07123456789',\n",
       " '0721072',\n",
       " '07732584351',\n",
       " '07734396839',\n",
       " '07742676969',\n",
       " '07753741225',\n",
       " '0776xxxxxxx',\n",
       " '07781482378',\n",
       " '07786200117',\n",
       " '077xxx',\n",
       " '078',\n",
       " '07801543489',\n",
       " '07808',\n",
       " '07808247860',\n",
       " '07808726822',\n",
       " '07815296484',\n",
       " '07821230901',\n",
       " '078498',\n",
       " '07880867867',\n",
       " '0789xxxxxxx',\n",
       " '07946746291',\n",
       " '0796xxxxxx',\n",
       " '07973788240',\n",
       " '07xxxxxxxxx',\n",
       " '08',\n",
       " '0800',\n",
       " '08000407165',\n",
       " '08000776320',\n",
       " '08000839402',\n",
       " '08000930705',\n",
       " '08000938767',\n",
       " '08001950382',\n",
       " '08002888812',\n",
       " '08002986030',\n",
       " '08002986906',\n",
       " '08002988890',\n",
       " '08006344447',\n",
       " '0808',\n",
       " '08081263000',\n",
       " '08081560665',\n",
       " '0825',\n",
       " '083',\n",
       " '0844',\n",
       " '08448350055',\n",
       " '08448714184',\n",
       " '0845',\n",
       " '08450542832',\n",
       " '08452810071',\n",
       " '08452810073',\n",
       " '08452810075over18',\n",
       " '0870',\n",
       " '08700435505150p',\n",
       " '08700469649',\n",
       " '08700621170150p',\n",
       " '08701213186',\n",
       " '08701237397',\n",
       " '08701417012',\n",
       " '08701417012150p',\n",
       " '0870141701216',\n",
       " '087016248',\n",
       " '08701752560',\n",
       " '087018728737',\n",
       " '0870241182716',\n",
       " '08702490080',\n",
       " '08702840625',\n",
       " '08704050406',\n",
       " '08704439680',\n",
       " '08704439680ts',\n",
       " '08706091795',\n",
       " '0870737910216yrs',\n",
       " '08707500020',\n",
       " '08707509020',\n",
       " '0870753331018',\n",
       " '08707808226',\n",
       " '08708034412',\n",
       " '08708800282',\n",
       " '08709222922',\n",
       " '08709501522',\n",
       " '0871',\n",
       " '087104711148',\n",
       " '08712101358',\n",
       " '08712103738',\n",
       " '0871212025016',\n",
       " '08712300220',\n",
       " '087123002209am',\n",
       " '08712317606',\n",
       " '08712400200',\n",
       " '08712400602450p',\n",
       " '08712400603',\n",
       " '08712402050',\n",
       " '08712402578',\n",
       " '08712402779',\n",
       " '08712402902',\n",
       " '08712402972',\n",
       " '08712404000',\n",
       " '08712405020',\n",
       " '08712405022',\n",
       " '08712460324',\n",
       " '08712466669',\n",
       " '0871277810710p',\n",
       " '0871277810810',\n",
       " '0871277810910p',\n",
       " '08714342399',\n",
       " '087147123779am',\n",
       " '08714712379',\n",
       " '08714712388',\n",
       " '08714712394',\n",
       " '08714712412',\n",
       " '08714714011',\n",
       " '08715203028',\n",
       " '08715203649',\n",
       " '08715203652',\n",
       " '08715203656',\n",
       " '08715203677',\n",
       " '08715203685',\n",
       " '08715203694',\n",
       " '08715205273',\n",
       " '08715500022',\n",
       " '08715705022',\n",
       " '08717111821',\n",
       " '08717168528',\n",
       " '08717205546',\n",
       " '0871750',\n",
       " '08717507382',\n",
       " '08717509990',\n",
       " '08717890890',\n",
       " '08717895698',\n",
       " '08717898035',\n",
       " '08718711108',\n",
       " '08718720201',\n",
       " '08718723815',\n",
       " '08718725756',\n",
       " '08718726270',\n",
       " '087187262701',\n",
       " '08718726970',\n",
       " '08718726971',\n",
       " '08718726978',\n",
       " '087187272008',\n",
       " '08718727868',\n",
       " '08718727870',\n",
       " '08718727870150ppm',\n",
       " '08718730555',\n",
       " '08718730666',\n",
       " '08718738001',\n",
       " '08718738002',\n",
       " '08718738034',\n",
       " '08719180219',\n",
       " '08719180248',\n",
       " '08719181259',\n",
       " '08719181503',\n",
       " '08719181513',\n",
       " '08719839835',\n",
       " '08719899217',\n",
       " '08719899229',\n",
       " '08719899230',\n",
       " '09',\n",
       " '09041940223',\n",
       " '09050000301',\n",
       " '09050000332',\n",
       " '09050000460',\n",
       " '09050000555',\n",
       " '09050000878',\n",
       " '09050000928',\n",
       " '09050001295',\n",
       " '09050001808',\n",
       " '09050002311',\n",
       " '09050003091',\n",
       " '09050005321',\n",
       " '09050090044',\n",
       " '09050280520',\n",
       " '09053750005',\n",
       " '09056242159',\n",
       " '09057039994',\n",
       " '09058091854',\n",
       " '09058091870',\n",
       " '09058094454',\n",
       " '09058094455',\n",
       " '09058094507',\n",
       " '09058094565',\n",
       " '09058094583',\n",
       " '09058094594',\n",
       " '09058094597',\n",
       " '09058094599',\n",
       " '09058095107',\n",
       " '09058095201',\n",
       " '09058097189',\n",
       " '09058097218',\n",
       " '09058098002',\n",
       " '09058099801',\n",
       " '09061104276',\n",
       " '09061104283',\n",
       " '09061209465',\n",
       " '09061213237',\n",
       " '09061221061',\n",
       " '09061221066',\n",
       " '09061701444',\n",
       " '09061701461',\n",
       " '09061701851',\n",
       " '09061701939',\n",
       " '09061702893',\n",
       " '09061743386',\n",
       " '09061743806',\n",
       " '09061743810',\n",
       " '09061743811',\n",
       " '09061744553',\n",
       " '09061749602',\n",
       " '09061790121',\n",
       " '09061790125',\n",
       " '09061790126',\n",
       " '09063440451',\n",
       " '09063442151',\n",
       " '09063458130',\n",
       " '0906346330',\n",
       " '09064011000',\n",
       " '09064012103',\n",
       " '09064012160',\n",
       " '09064015307',\n",
       " '09064017295',\n",
       " '09064017305',\n",
       " '09064018838',\n",
       " '09064019014',\n",
       " '09064019788',\n",
       " '09065069120',\n",
       " '09065069154',\n",
       " '09065171142',\n",
       " '09065174042',\n",
       " '09065394514',\n",
       " '09065394973',\n",
       " '09065989180',\n",
       " '09065989182',\n",
       " '09066350750',\n",
       " '09066358152',\n",
       " '09066358361',\n",
       " '09066361921',\n",
       " '09066362206',\n",
       " '09066362220',\n",
       " '09066362231',\n",
       " '09066364311',\n",
       " '09066364349',\n",
       " '09066364589',\n",
       " '09066368327',\n",
       " '09066368470',\n",
       " '09066368753',\n",
       " '09066380611',\n",
       " '09066382422',\n",
       " '09066612661',\n",
       " '09066649731from',\n",
       " '09066660100',\n",
       " '09071512432',\n",
       " '09071512433',\n",
       " '09071517866',\n",
       " '09077818151',\n",
       " '09090204448',\n",
       " '09090900040',\n",
       " '09094100151',\n",
       " '09094646631',\n",
       " '09094646899',\n",
       " '09095350301',\n",
       " '09096102316',\n",
       " '09099725823',\n",
       " '09099726395',\n",
       " '09099726429',\n",
       " '09099726481',\n",
       " '09099726553',\n",
       " '09111030116',\n",
       " '09111032124',\n",
       " '09701213186',\n",
       " '0a',\n",
       " '0quit',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '1000call',\n",
       " '1000s',\n",
       " '100p',\n",
       " '100percent',\n",
       " '100txt',\n",
       " '1013',\n",
       " '1030',\n",
       " '10am',\n",
       " '10k',\n",
       " '10p',\n",
       " '10ppm',\n",
       " '10th',\n",
       " '11',\n",
       " '1120',\n",
       " '113',\n",
       " '1131',\n",
       " '114',\n",
       " '116',\n",
       " '1172',\n",
       " '118p',\n",
       " '11mths',\n",
       " '11pm',\n",
       " '12',\n",
       " '1205',\n",
       " '120p',\n",
       " '121',\n",
       " '1225',\n",
       " '123',\n",
       " '125',\n",
       " '1250',\n",
       " '125gift',\n",
       " '128',\n",
       " '12hours',\n",
       " '12hrs',\n",
       " '12mths',\n",
       " '13',\n",
       " '130',\n",
       " '1327',\n",
       " '139',\n",
       " '14',\n",
       " '140',\n",
       " '1405',\n",
       " '140ppm',\n",
       " '145',\n",
       " '1450',\n",
       " '146tf150p',\n",
       " '14tcr',\n",
       " '14thmarch',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '150p',\n",
       " '150p16',\n",
       " '150pm',\n",
       " '150ppermesssubscription',\n",
       " '150ppm',\n",
       " '150ppmpobox10183bhamb64xe',\n",
       " '150ppmsg',\n",
       " '150pw',\n",
       " '151',\n",
       " '153',\n",
       " '15541',\n",
       " '15pm',\n",
       " '16',\n",
       " '165',\n",
       " '1680',\n",
       " '169',\n",
       " '177',\n",
       " '18',\n",
       " '180',\n",
       " '1843',\n",
       " '18p',\n",
       " '18yrs',\n",
       " '195',\n",
       " '1956669',\n",
       " '1apple',\n",
       " '1b6a5ecef91ff9',\n",
       " '1cup',\n",
       " '1da',\n",
       " '1er',\n",
       " '1hr',\n",
       " '1im',\n",
       " '1lemon',\n",
       " '1mega',\n",
       " '1million',\n",
       " '1pm',\n",
       " '1st',\n",
       " '1st4terms',\n",
       " '1stchoice',\n",
       " '1stone',\n",
       " '1thing',\n",
       " '1tulsi',\n",
       " '1win150ppmx3',\n",
       " '1winaweek',\n",
       " '1winawk',\n",
       " '1x150p',\n",
       " '1yf',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '200p',\n",
       " '2025050',\n",
       " '20m12aq',\n",
       " '20p',\n",
       " '21',\n",
       " '21870000',\n",
       " '21st',\n",
       " '22',\n",
       " '220',\n",
       " '220cm2',\n",
       " '2309',\n",
       " '23f',\n",
       " '23g',\n",
       " '24',\n",
       " '24hrs',\n",
       " '24m',\n",
       " '24th',\n",
       " '25',\n",
       " '250',\n",
       " '250k',\n",
       " '255',\n",
       " '25p',\n",
       " '26',\n",
       " '2667',\n",
       " '26th',\n",
       " '27',\n",
       " '28',\n",
       " '2814032',\n",
       " '28days',\n",
       " '28th',\n",
       " '28thfeb',\n",
       " '29',\n",
       " '2b',\n",
       " '2bold',\n",
       " '2c',\n",
       " '2channel',\n",
       " '2day',\n",
       " '2end',\n",
       " '2exit',\n",
       " '2ez',\n",
       " '2find',\n",
       " '2getha',\n",
       " '2geva',\n",
       " '2go',\n",
       " '2gthr',\n",
       " '2hrs',\n",
       " '2kbsubject',\n",
       " '2lands',\n",
       " '2marrow',\n",
       " '2moro',\n",
       " '2morow',\n",
       " '2morro',\n",
       " '2morrow',\n",
       " '2morrowxxxx',\n",
       " '2mro',\n",
       " '2mrw',\n",
       " '2nd',\n",
       " '2nhite',\n",
       " '2nights',\n",
       " '2nite',\n",
       " '2optout',\n",
       " '2p',\n",
       " '2price',\n",
       " '2px',\n",
       " '2rcv',\n",
       " '2stop',\n",
       " '2stoptx',\n",
       " '2stoptxt',\n",
       " '2u',\n",
       " '2u2',\n",
       " '2waxsto',\n",
       " '2wks',\n",
       " '2wt',\n",
       " '2wu',\n",
       " '2years',\n",
       " '2yr',\n",
       " '2yrs',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '300603',\n",
       " '300603t',\n",
       " '300p',\n",
       " '3030',\n",
       " '30apr',\n",
       " '30ish',\n",
       " '30pm',\n",
       " '30pp',\n",
       " '30s',\n",
       " '30th',\n",
       " '31',\n",
       " '3100',\n",
       " '310303',\n",
       " '31p',\n",
       " '32',\n",
       " '32000',\n",
       " '3230',\n",
       " '32323',\n",
       " '326',\n",
       " '33',\n",
       " '330',\n",
       " '350',\n",
       " '3510i',\n",
       " '35p',\n",
       " '3650',\n",
       " '36504',\n",
       " '3680',\n",
       " '373',\n",
       " '3750',\n",
       " '37819',\n",
       " '38',\n",
       " '382',\n",
       " '391784',\n",
       " '3aj',\n",
       " '3d',\n",
       " '3days',\n",
       " '3g',\n",
       " '3gbp',\n",
       " '3hrs',\n",
       " '3lions',\n",
       " '3lp',\n",
       " '3miles',\n",
       " '3mins',\n",
       " '3mobile',\n",
       " '3optical',\n",
       " '3pound',\n",
       " '3qxj9',\n",
       " '3rd',\n",
       " '3ss',\n",
       " '3uz',\n",
       " '3wks',\n",
       " '3xx',\n",
       " '3x',\n",
       " '40',\n",
       " '400',\n",
       " '400mins',\n",
       " '400thousad',\n",
       " '402',\n",
       " '4041',\n",
       " '40411',\n",
       " '40533',\n",
       " '40gb',\n",
       " '40mph',\n",
       " '41685',\n",
       " '41782',\n",
       " '420',\n",
       " '42049',\n",
       " '4217',\n",
       " '42478',\n",
       " '42810',\n",
       " '430',\n",
       " '434',\n",
       " '44',\n",
       " '440',\n",
       " '4403ldnw1a7rw18',\n",
       " '44345',\n",
       " '447797706009',\n",
       " '447801259231',\n",
       " '448712404000',\n",
       " '449050000301',\n",
       " '449071512431',\n",
       " '45',\n",
       " '450',\n",
       " '450p',\n",
       " '450pw',\n",
       " '45239',\n",
       " '45pm',\n",
       " '47',\n",
       " '4719',\n",
       " '4742',\n",
       " '47per',\n",
       " '48',\n",
       " '4882',\n",
       " '48922',\n",
       " '49',\n",
       " '49557',\n",
       " '4a',\n",
       " '4d',\n",
       " '4eva',\n",
       " '4few',\n",
       " '4fil',\n",
       " '4get',\n",
       " '4give',\n",
       " '4got',\n",
       " '4goten',\n",
       " '4info',\n",
       " '4jx',\n",
       " '4msgs',\n",
       " '4mths',\n",
       " '4qf2',\n",
       " '4t',\n",
       " '4th',\n",
       " '4the',\n",
       " '4thnov',\n",
       " '4txt',\n",
       " '4u',\n",
       " '4utxt',\n",
       " '4w',\n",
       " '4ward',\n",
       " '4wrd',\n",
       " '4xx26',\n",
       " '4years',\n",
       " '50',\n",
       " '500',\n",
       " '5000',\n",
       " '505060',\n",
       " '50award',\n",
       " '50ea',\n",
       " '50gbp',\n",
       " '50p',\n",
       " '50perweeksub',\n",
       " '50perwksub',\n",
       " '50pm',\n",
       " '50pmmorefrommobile2bremoved',\n",
       " '50ppm',\n",
       " '50rcvd',\n",
       " '50s',\n",
       " '515',\n",
       " '5226',\n",
       " '523',\n",
       " '526',\n",
       " '528',\n",
       " '530',\n",
       " '54',\n",
       " '542',\n",
       " '545',\n",
       " '5digital',\n",
       " '5free',\n",
       " '5ish',\n",
       " '5k',\n",
       " '5min',\n",
       " '5mls',\n",
       " '5p',\n",
       " '5pm',\n",
       " '5th',\n",
       " '5wb',\n",
       " '5we',\n",
       " '5wkg',\n",
       " '5wq',\n",
       " '5years',\n",
       " '60',\n",
       " '600',\n",
       " '6031',\n",
       " '6089',\n",
       " '60p',\n",
       " '61',\n",
       " '61200',\n",
       " '61610',\n",
       " '62220cncl',\n",
       " '6230',\n",
       " '62468',\n",
       " '62735',\n",
       " '630',\n",
       " '63miles',\n",
       " '645',\n",
       " '65',\n",
       " '650',\n",
       " '66',\n",
       " '6669',\n",
       " '674',\n",
       " '67441233',\n",
       " '68866',\n",
       " '69101',\n",
       " '69200',\n",
       " '69669',\n",
       " '69696',\n",
       " '69698',\n",
       " '69855',\n",
       " '69866',\n",
       " '69876',\n",
       " '69888',\n",
       " '69888nyt',\n",
       " '69911',\n",
       " '69969',\n",
       " '69988',\n",
       " '6days',\n",
       " '6hl',\n",
       " '6hrs',\n",
       " '6ish',\n",
       " '6missed',\n",
       " '6months',\n",
       " '6ph',\n",
       " '6pm',\n",
       " '6th',\n",
       " '6times',\n",
       " '6wu',\n",
       " '6zf',\n",
       " '700',\n",
       " '71',\n",
       " '7250',\n",
       " '7250i',\n",
       " '730',\n",
       " '731',\n",
       " '74355',\n",
       " '75',\n",
       " '750',\n",
       " '7548',\n",
       " '75max',\n",
       " '762',\n",
       " '7634',\n",
       " '7684',\n",
       " '77',\n",
       " '7732584351',\n",
       " '78',\n",
       " '786',\n",
       " '7876150ppm',\n",
       " '79',\n",
       " '7am',\n",
       " '7cfca1a',\n",
       " '7ish',\n",
       " '7mp',\n",
       " '7oz',\n",
       " '7pm',\n",
       " '7th',\n",
       " '7ws',\n",
       " '7zs',\n",
       " '80',\n",
       " '800',\n",
       " '8000930705',\n",
       " '80062',\n",
       " '8007',\n",
       " '80082',\n",
       " '80086',\n",
       " '80122300p',\n",
       " '80155',\n",
       " '80160',\n",
       " '80182',\n",
       " '8027',\n",
       " '80488',\n",
       " '80608',\n",
       " '8077',\n",
       " '80878',\n",
       " '81010',\n",
       " '81151',\n",
       " '81303',\n",
       " '81618',\n",
       " '82050',\n",
       " '820554ad0a1705572711',\n",
       " '82242',\n",
       " '82277',\n",
       " '82324',\n",
       " '82468',\n",
       " '83021',\n",
       " '83039',\n",
       " '83049',\n",
       " '83110',\n",
       " '83118',\n",
       " '83222',\n",
       " '83332',\n",
       " '83338',\n",
       " '83355',\n",
       " '83370',\n",
       " '83383',\n",
       " '83435',\n",
       " '83600',\n",
       " '83738',\n",
       " '84',\n",
       " '84025',\n",
       " '84122',\n",
       " '84128',\n",
       " '84199',\n",
       " '84484',\n",
       " '85',\n",
       " '850',\n",
       " '85023',\n",
       " '85069',\n",
       " '85222',\n",
       " '85233',\n",
       " '8552',\n",
       " '85555',\n",
       " '86021',\n",
       " '861',\n",
       " '864233',\n",
       " '86688',\n",
       " '86888',\n",
       " '87021',\n",
       " '87066',\n",
       " '87070',\n",
       " '87077',\n",
       " '87121',\n",
       " '87131',\n",
       " '8714714',\n",
       " '872',\n",
       " '87239',\n",
       " '87575',\n",
       " '8800',\n",
       " '88039',\n",
       " '88066',\n",
       " '88088',\n",
       " '88222',\n",
       " '88600',\n",
       " '88800',\n",
       " '8883',\n",
       " '88877',\n",
       " '88888',\n",
       " '89034',\n",
       " '89070',\n",
       " '89080',\n",
       " '89105',\n",
       " '89123',\n",
       " '89545',\n",
       " '89555',\n",
       " '89693',\n",
       " '89938',\n",
       " '8am',\n",
       " '8ball',\n",
       " '8lb',\n",
       " '8p',\n",
       " '8pm',\n",
       " '8th',\n",
       " '8wp',\n",
       " '900',\n",
       " '9061100010',\n",
       " '910',\n",
       " '9153',\n",
       " '9280114',\n",
       " '930',\n",
       " '9307622',\n",
       " '945',\n",
       " '946',\n",
       " '95',\n",
       " '9755',\n",
       " '9758',\n",
       " '97n7qp',\n",
       " '98321561',\n",
       " '99',\n",
       " '9996',\n",
       " '9ae',\n",
       " '9am',\n",
       " '9ja',\n",
       " '9pm',\n",
       " '9t',\n",
       " '9th',\n",
       " '9yt',\n",
       " '____',\n",
       " 'a21',\n",
       " 'a30',\n",
       " 'aa',\n",
       " 'aah',\n",
       " 'aaniye',\n",
       " 'aaooooright',\n",
       " 'aathi',\n",
       " 'ab',\n",
       " 'abbey',\n",
       " 'abdomen',\n",
       " 'abeg',\n",
       " 'abel',\n",
       " 'aberdeen',\n",
       " 'abi',\n",
       " 'ability',\n",
       " 'abiola',\n",
       " 'abj',\n",
       " 'able',\n",
       " 'abnormally',\n",
       " 'about',\n",
       " 'aboutas',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'absence',\n",
       " 'absolutely',\n",
       " 'absolutly',\n",
       " 'abstract',\n",
       " 'abt',\n",
       " 'abta',\n",
       " 'aburo',\n",
       " 'abuse',\n",
       " 'abusers',\n",
       " 'ac',\n",
       " 'academic',\n",
       " 'acc',\n",
       " 'accent',\n",
       " 'accenture',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accessible',\n",
       " 'accidant',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accommodation',\n",
       " 'accommodationvouchers',\n",
       " 'accomodate',\n",
       " 'accomodations',\n",
       " 'accordin',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'accumulation',\n",
       " 'achan',\n",
       " 'ache',\n",
       " 'achieve',\n",
       " 'acid',\n",
       " 'acknowledgement',\n",
       " 'acl03530150pm',\n",
       " 'acnt',\n",
       " 'aco',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'actin',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'activ8',\n",
       " 'activate',\n",
       " 'active',\n",
       " 'activities',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'add',\n",
       " 'addamsfa',\n",
       " 'added',\n",
       " 'addicted',\n",
       " 'addie',\n",
       " 'adding',\n",
       " 'address',\n",
       " 'adds',\n",
       " 'adewale',\n",
       " 'adi',\n",
       " 'adjustable',\n",
       " 'admin',\n",
       " 'administrator',\n",
       " 'admirer',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'adore',\n",
       " 'adoring',\n",
       " 'adp',\n",
       " 'adress',\n",
       " 'adrian',\n",
       " 'ads',\n",
       " 'adsense',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'adventure',\n",
       " 'adventuring',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advising',\n",
       " 'advisors',\n",
       " 'aeronautics',\n",
       " 'aeroplane',\n",
       " 'afew',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affections',\n",
       " 'affidavit',\n",
       " 'afford',\n",
       " 'afghanistan',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'aft',\n",
       " 'after',\n",
       " 'afternon',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'afterwards',\n",
       " 'aftr',\n",
       " 'ag',\n",
       " 'again',\n",
       " 'against',\n",
       " 'agalla',\n",
       " 'age',\n",
       " 'age16',\n",
       " 'age23',\n",
       " 'agency',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'agidhane',\n",
       " 'aging',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'ahmad',\n",
       " 'ahold',\n",
       " 'aid',\n",
       " 'aids',\n",
       " 'aig',\n",
       " 'aight',\n",
       " 'ain',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'air1',\n",
       " 'airport',\n",
       " ...]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a294df0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>_</th>\n",
       "      <th>_</th>\n",
       "      <th>_thanks</th>\n",
       "      <th>m</th>\n",
       "      <th>t</th>\n",
       "      <th>ve</th>\n",
       "      <th></th>\n",
       "      <th>harry</th>\n",
       "      <th></th>\n",
       "      <th>well</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows  8672 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  000pes  008704050406  0089  0121  01223585236  01223585334  \\\n",
       "0      0    0       0             0     0     0            0            0   \n",
       "1      0    0       0             0     0     0            0            0   \n",
       "2      0    0       0             0     0     0            0            0   \n",
       "3      0    0       0             0     0     0            0            0   \n",
       "4      0    0       0             0     0     0            0            0   \n",
       "...   ..  ...     ...           ...   ...   ...          ...          ...   \n",
       "5567   0    0       0             0     0     0            0            0   \n",
       "5568   0    0       0             0     0     0            0            0   \n",
       "5569   0    0       0             0     0     0            0            0   \n",
       "5570   0    0       0             0     0     0            0            0   \n",
       "5571   0    0       0             0     0     0            0            0   \n",
       "\n",
       "      0125698789  02  ...  _  _  _thanks  m  t  ve    harry    \\\n",
       "0              0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "1              0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "2              0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "3              0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "4              0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "...          ...  ..  ...  ..  ..       ...  ...  ...   ...  ..      ...  ..   \n",
       "5567           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "5568           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "5569           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "5570           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "5571           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "\n",
       "      well  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "5567       0  \n",
       "5568       0  \n",
       "5569       0  \n",
       "5570       0  \n",
       "5571       0  \n",
       "\n",
       "[5572 rows x 8672 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = pd.DataFrame(X_bag_of_words.todense(), columns = count_vect.get_feature_names())\n",
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c83eb066",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train['predicted'] = lm.predict(X_train)\n",
    "test['predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "45ea4be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.58%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3857   106\n",
      "spam          2   492\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      3859\n",
      "        spam       1.00      0.82      0.90       598\n",
      "\n",
      "    accuracy                           0.98      4457\n",
      "   macro avg       0.98      0.91      0.94      4457\n",
      "weighted avg       0.98      0.98      0.97      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f1fc47af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.68%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        965    36\n",
      "spam         1   113\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98       966\n",
      "        spam       0.99      0.76      0.86       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.88      0.92      1115\n",
      "weighted avg       0.97      0.97      0.96      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20245528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
